{"cells":[{"cell_type":"markdown","metadata":{"id":"IcSXhRvnZc0g"},"source":["# DR-HQCL: A Fusion of Supervised Contrastive Learning and Variational Quantum Classifiers"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Environment Setup"]},{"cell_type":"markdown","metadata":{},"source":["### 1.1 Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1047,"status":"ok","timestamp":1690111765411,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"GpranR556llp"},"outputs":[],"source":["import os\n","from datetime import datetime"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5553,"status":"ok","timestamp":1690111770960,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"aQPVmAIFesJP"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","import torchvision.utils as utils\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, ConcatDataset, Dataset\n","from torchsummary import summary\n","from torch.optim import lr_scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1562,"status":"ok","timestamp":1690111772517,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"IAqjx7h6b8pz"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.pipeline import make_pipeline\n","from sklearn.decomposition import PCA\n","from sklearn.neighbors import LocalOutlierFactor\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.linear_model import RidgeClassifier, LogisticRegression, SGDClassifier, Perceptron, PassiveAggressiveClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from matplotlib.colors import ListedColormap"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from qiskit.utils import algorithm_globals\n","from qiskit_machine_learning.datasets import ad_hoc_data\n","from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n","from qiskit import BasicAer, execute\n","from qiskit_machine_learning.algorithms.classifiers import VQC\n","from qiskit.algorithms.optimizers import SPSA, COBYLA"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3707,"status":"ok","timestamp":1690111794233,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"smn7Z4z4iSUn"},"outputs":[],"source":["from utility.plot import plot_roc, plot_confusion_matrix, plot_classification_report, plot_losses, plot_accuracies\n","from utility.dataset import load_dataset, get_stats, download_and_extract_data, SmallDataset, create_small_dataset, get_data_class, convert_2048_features,scale_dataset, create_new_dataframe_and_save_csv\n","from utility.predict import get_accuracy, test_classifiers, train_model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import medmnist\n","from medmnist import INFO, Evaluator"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["### 1.2. Set Random Seed Settings"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.manual_seed(42)\n","np.random.seed(42)"]},{"cell_type":"markdown","metadata":{},"source":["### 1.3. Device Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1690111794234,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"fFgHrxFO7LnK"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["### 1.4 Creating Directories\n","Creating directories to store experiment results, machine learning models, and data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","results_dir = f\"./experiments/+{str(datetime.now().strftime('%Y_%m_%d_%H_%M_%S'))}/\"\n","\n","if not os.path.exists(results_dir):\n","    # If not, create the folder\n","    os.makedirs(results_dir)\n","    print(f\"Folder '{results_dir}' created successfully.\")\n","else:\n","    print(f\"Folder '{results_dir}' already exists.\")\n","\n","models_dir = f\"./models/{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}/\"\n","\n","if not os.path.exists(models_dir):\n","    # If not, create the folder\n","    os.makedirs(models_dir)\n","    print(f\"Folder '{models_dir}' created successfully.\")\n","else:\n","    print(f\"Folder '{models_dir}' already exists.\")\n","\n","data_dir = f\"./data/\"\n","\n","if not os.path.exists(data_dir):\n","    # If not, create the folder\n","    os.makedirs(data_dir)\n","    print(f\"Folder '{data_dir}' created successfully.\")\n","else:\n","    print(f\"Folder '{data_dir}' already exists.\")"]},{"cell_type":"markdown","metadata":{},"source":["### 1.5 Download Data\n","Download hymenoptera data and kaggle data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["destination_folder = \"./data\"\n","\n","hymenoptera_url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n","cats_dogs_url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n","\n","download_and_extract_data(hymenoptera_url, destination_folder)\n","download_and_extract_data(cats_dogs_url, destination_folder)"]},{"cell_type":"markdown","metadata":{"id":"wFINY1xFesJP"},"source":["## 2. Dataset Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1690111794235,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"_yYNVSG3x0Pi"},"outputs":[],"source":["input_shape = (32, 32, 3)\n","learning_rate = 0.001\n","batch_size = 256\n","hidden_units = 512\n","projection_units = 128\n","num_epochs = 50\n","dropout_rate = 0.5\n","temperature = 0.01\n","gamma_lr_scheduler = 0.01"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 Transform datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# preprocessing\n","data_transforms = transforms.Compose([\n","    transforms.Resize(input_shape[0]),\n","    transforms.Grayscale(3),\n","    transforms.ToTensor(),\n","    # transforms.Normalize(mean=[.5], std=[.5])\n","])"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2 Create small datasets"]},{"cell_type":"markdown","metadata":{},"source":["#### 2.2.1 Create training and testing datasets for hymenoptera ants & bees"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5647,"status":"ok","timestamp":1690111799876,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"52mDBoBwPsvY","outputId":"fc634fc6-7eab-4dba-9dbe-d95ae6793ef9"},"outputs":[],"source":["train_dataset_1, test_dataset_1, _, \\\n","    _, dataset_sizes_1, class_names_1, y_train_1, y_test_1 = \\\n","        load_dataset( input_shape, batch_size, \"data/hymenoptera_data\", data_transforms )\n","\n","# encapsulate data into dataloader form\n","train_loader_1 = create_small_dataset( 100, train_dataset_1, batch_size )\n","test_loader_1 = create_small_dataset( 20, test_dataset_1, batch_size )"]},{"cell_type":"markdown","metadata":{},"source":["#### 2.2.2 Create training and testing datasets for kaglle cats & dogs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataset_2, test_dataset_2, _, \\\n","    _, dataset_sizes_2, class_names_2, y_train_2, y_test_2 = \\\n","        load_dataset( input_shape, batch_size, \"data/PetImages\", data_transforms )\n","\n","train_loader_2 = create_small_dataset( 100, train_dataset_2, batch_size )\n","test_loader_2 = create_small_dataset( 20, test_dataset_2, batch_size )"]},{"cell_type":"markdown","metadata":{},"source":["#### 2.2.2 Create training and testing datasets for MedMNIST2D datasets\n","Below is a example of how to load 'breastmnist' MedMNIST2D dataset. This need to be done for 'PneumoniaMNIST', 'BreastMNIST', 'PathMNIST', 'ChestMNIST' datasets."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load the data\n","BreastMNISTDataClass = get_data_class('breastmnist')\n","train_dataset_3 = BreastMNISTDataClass(split='train', transform=data_transforms, download=True)\n","test_dataset_3 = BreastMNISTDataClass(split='test', transform=data_transforms, download=True)\n","\n","train_loader_3 = create_small_dataset( 100, train_dataset_3, batch_size )\n","test_loader_3 = create_small_dataset( 20, test_dataset_3, batch_size )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# concatenated_dataset = ConcatDataset([train_loader.dataset, test_loader.dataset])\n","# merged_dataloader = DataLoader(concatenated_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Hybrid Quantum-Classical Supervised Contrastive Learning"]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 Classical supervised contrastive learning"]},{"cell_type":"markdown","metadata":{"id":"F4D6BjwN8d1N"},"source":["[Supervised Contrastive Learning](https://arxiv.org/abs/2004.11362)\n","(Prannay Khosla et al.) is a training methodology that outperforms\n","supervised training with crossentropy on classification tasks.\n","\n","Essentially, training an image classification model with Supervised Contrastive\n","Learning is performed in two phases:\n","\n","1. Training an encoder to learn to produce vector representations of input images such\n","that representations of images in the same class will be more similar compared to\n","representations of images in different classes.\n","2. Training a classifier on top of the frozen encoder.\n","\n","![Classical Supervised Contrastive Learning](images/img_1.png)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 Our Proposed Hybrid Quantum Classical Supervised Contrastive Learning Model (DR-HQCL)"]},{"cell_type":"markdown","metadata":{},"source":["![Hybrid Quantum-Classical Supervised Contrastive Learning](images/img_2.png)"]},{"cell_type":"markdown","metadata":{"id":"ghQbDuIkesJQ"},"source":["### 3.3 Data augmentation"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.3.1 Get mean, std details about all the datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["total_mean_1, total_std_1 = get_stats(train_loader_1, test_loader_1, input_shape)\n","# todo: calculate mean, std for all other datasets."]},{"cell_type":"markdown","metadata":{},"source":["#### 3.3.2 Create data augmentation layer with 5 operations"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1690112081515,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"q-Gch3wfr9O8"},"outputs":[],"source":["hFlip = transforms.RandomHorizontalFlip()\n","rRotation = transforms.RandomRotation(2)\n","rAffine = transforms.RandomAffine(degrees=0, translate=(0.2, 0.2))\n","cJitter = transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)  # Randomly adjust color\n","\n","data_augmentation_1 = torch.nn.Sequential(\n","    transforms.Normalize(mean=total_mean_1, std=total_std_1),\n","    hFlip,\n","    rRotation,\n","    rAffine,\n","    cJitter\n",")"]},{"cell_type":"markdown","metadata":{"id":"N96QdI-ZesJR"},"source":["### 3.4 Build the classical encoder model\n","\n","The encoder model takes the image as input and turns it into a 2048-dimensional\n","feature vector."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1690112081515,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"FdYcG0bGv_Lx"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, data_augmentation, pretrained=False):\n","        super(Encoder, self).__init__()\n","        enc = models.resnet50(pretrained=pretrained)\n","        # Remove last layer\n","        enc.fc = nn.Identity()\n","        self.enc = enc\n","        self.data_augmentation = data_augmentation\n","\n","    def forward(self, x):\n","        augmented = self.data_augmentation(x)\n","        outputs = self.enc(augmented)\n","        return outputs"]},{"cell_type":"markdown","metadata":{},"source":["### 3.5 Build projection head"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ProjectionHead(nn.Module):\n","    def __init__(self, encoder, projection_units):\n","        super(ProjectionHead, self).__init__()\n","        self.encoder = encoder\n","        self.fc1 = nn.Linear(2048, projection_units)\n","        self.relu1 = nn.ReLU()\n","\n","    def forward(self, x):\n","        features = self.encoder(x)\n","        outputs = self.relu1(self.fc1(features))\n","        return outputs"]},{"cell_type":"markdown","metadata":{"id":"wzSw106fesJR"},"source":["### 3.6 Build the classical neural network (NN) classification model for benchmarking\n","\n","The classification model adds a fully-connected layer on top of the encoder,\n","plus a softmax layer with the target classes."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1690112081516,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"TL5IuHLgw1GO"},"outputs":[],"source":["class Classifier(nn.Module):\n","    def __init__(self, encoder, hidden_units, num_classes, dropout_rate, trainable=True):\n","        super(Classifier, self).__init__()\n","        self.encoder = encoder\n","        if not trainable:\n","            for param in self.encoder.parameters():\n","                param.requires_grad = False\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.fc1 = nn.Linear(2048, hidden_units)\n","        self.fc2 = nn.Linear(hidden_units, num_classes)\n","        self.relu1 = nn.ReLU()\n","        self.softmax1 = nn.Softmax()\n","\n","    def forward(self, x):\n","        features = self.encoder(x)\n","        features = self.dropout(features)\n","        features = self.relu1(self.fc1(features))\n","        features = self.dropout(features)\n","        outputs = self.softmax1(self.fc2(features))\n","        return outputs"]},{"cell_type":"markdown","metadata":{},"source":["### 3.7 Build variational quantum classification (VQC) model for benchmarking"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.7.1 Create a log for the optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class OptimizerLog:\n","    \"\"\"Log to store optimizer's intermediate results\"\"\"\n","    def __init__(self):\n","        self.evaluations = []\n","        self.parameters = []\n","        self.costs = []\n","    def update(self, evaluation, parameter, cost, _stepsize, _accept):\n","        \"\"\"Save intermediate results. Optimizer passes five values\n","        but we ignore the last two.\"\"\"\n","        self.evaluations.append(evaluation)\n","        self.parameters.append(parameter)\n","        self.costs.append(cost)"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.7.2 Build feature map for data encoding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["FEATURE_MAP = ZZFeatureMap(feature_dimension=2, reps=2)"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.7.3 Build variational circuit for learning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["VAR_FORM = TwoLocal(2, ['ry', 'rz'], 'cz', reps=2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["VQC_CIRCUIT = FEATURE_MAP.compose(VAR_FORM)\n","VQC_CIRCUIT.measure_all()\n","VQC_CIRCUIT.decompose().draw()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# VQC_CIRCUIT.draw(output='mpl', style='iqx')"]},{"cell_type":"markdown","metadata":{"id":"RoSMT3dTesJS"},"source":["## 4. Model training\n","\n","In this experiment, the model is trained in two phases. In the first phase,\n","the encoder is pretrained to optimize the supervised contrastive loss,\n","described in [Prannay Khosla et al.](https://arxiv.org/abs/2004.11362).\n","\n","In the second phase, the variational quantum classifier is trained using the trained encoder with\n","its weights freezed; only the weights of fully-connected layers with the\n","softmax are optimized."]},{"cell_type":"markdown","metadata":{},"source":["### 4.1 Supervised contrastive learning loss function"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":581,"status":"ok","timestamp":1690113681845,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"39_K7dWQxKhv"},"outputs":[],"source":["class SupervisedContrastiveLoss(nn.Module):\n","    def __init__(self, temperature=1):\n","        super(SupervisedContrastiveLoss, self).__init__()\n","        self.temperature = temperature\n","        print(self.temperature)\n","\n","    def forward(self, feature_vectors, labels):\n","        print(feature_vectors.shape)\n","        # Normalize feature vectors\n","        feature_vectors_normalized = F.normalize(feature_vectors, p=2, dim=1)\n","        # Compute logits\n","        logits = torch.div(torch.matmul(feature_vectors_normalized, feature_vectors_normalized.t()), self.temperature)\n","        # Compute the loss using npairs_loss\n","        loss = F.cross_entropy( logits, labels.squeeze() )\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"1lw7nm48esJT"},"source":["### 4.2 Pretrain the encoder and Save the model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":390,"status":"ok","timestamp":1690113686274,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"99FXnDW3iTPm"},"outputs":[],"source":["encoder = Encoder(data_augmentation_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":499,"status":"ok","timestamp":1690113686770,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"chVPi02ye7b8"},"outputs":[],"source":["# Load saved model\n","# encoder.load_state_dict(torch.load('models/encoder'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Move the models to GPU if available\n","encoder.to(device);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pUxhaj-5yvwR"},"outputs":[],"source":["# Create an instance of the encoder with projection head\n","encoder_with_projection_head = ProjectionHead(encoder, projection_units)\n","\n","# Move the models to GPU if available\n","encoder_with_projection_head.to(device);"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":400,"status":"ok","timestamp":1690113697254,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"qQASHwnIOaZk"},"outputs":[],"source":["# Define the optimizer\n","encoderOptimizer = optim.Adam(encoder_with_projection_head.parameters(), lr=learning_rate)\n","# encoderOptimizer = optim.SGD(encoder_with_projection_head.parameters(), lr=learning_rate)\n","encoderCriterion = SupervisedContrastiveLoss(temperature=temperature)\n","encoder_exp_lr_scheduler = lr_scheduler.StepLR(\n","    encoderOptimizer, step_size=10, gamma=gamma_lr_scheduler\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":571},"executionInfo":{"elapsed":510,"status":"error","timestamp":1690113698181,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"JBk5Cjuck9tQ","outputId":"0dd873b6-b0f6-43af-ae31-e9abccff647e"},"outputs":[],"source":["# Training loop\n","train_loss_history, train_acc_history, val_loss_history, val_acc_history = \\\n","    train_model(encoder_with_projection_head, encoderCriterion, encoderOptimizer, \\\n","                encoder_exp_lr_scheduler, train_loader_1, test_loader_1, num_epochs, \\\n","                    validation=False, regularize=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(plot_losses(range(num_epochs), [\n","    train_loss_history\n","], ['Train Loss'], 'Encoder Losses', results_dir+\"/enc_loss.png\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1690103933970,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"m0qHqMzM_iuy"},"outputs":[],"source":["torch.save(encoder_with_projection_head.state_dict(), models_dir+'/'+'encoder_with_projection_head')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1690103934499,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"fQeiLrcdwnQx"},"outputs":[],"source":["torch.save(encoder.state_dict(), models_dir+'/'+'encoder')"]},{"cell_type":"markdown","metadata":{"id":"2CnxCco3esJU"},"source":["### 4.3 Train the NN classifier with the frozen encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FoUwQ377mKQV"},"outputs":[],"source":["# Create an instance of the classifier\n","classifier = Classifier(encoder, hidden_units, len(class_names_1), dropout_rate, trainable=False)\n","# Move the models to GPU if available\n","classifier.to(device);"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":302,"status":"ok","timestamp":1690109659311,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"gF5Ph8I5fop5"},"outputs":[],"source":["# classifier.load_state_dict(torch.load(f'{models_dir}/classifier'))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1690109661848,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"nR0MdjASfpO-"},"outputs":[],"source":["classifierCriterion = nn.CrossEntropyLoss()\n","classifierOptimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n","classifier_exp_lr_scheduler = lr_scheduler.StepLR(\n","    classifierOptimizer, step_size=5, gamma=gamma_lr_scheduler\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":962474,"status":"ok","timestamp":1690110643349,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"07aEbXRmzpTZ","outputId":"862817ba-3122-4b60-b620-d16462e982c4"},"outputs":[],"source":["train_loss_history2, train_acc_history2 = train_model(classifier, classifierCriterion, classifierOptimizer, classifier_exp_lr_scheduler, train_loader_1, 100, regularize=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":512,"status":"ok","timestamp":1689750126703,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"rkvNs8L_BPTI"},"outputs":[],"source":["torch.save(classifier.state_dict(), f'{models_dir}/classifier')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0oFXutnOaEN"},"outputs":[],"source":["print(plot_losses(range(100), [\n","    train_loss_history2,\n","], ['Train Loss'], 'Classifier Losses (With Pre-Trained Auto-Encoder)', results_dir+\"/with_ae_loss\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":532,"status":"ok","timestamp":1689750617773,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"bOZTpFDj0l98"},"outputs":[],"source":["print(plot_accuracies(range(100), [\n","    train_acc_history2\n","], ['Train Accurcy'], 'Classifier Accuracies (With Pre-Trained Auto-Encoder)', results_dir+\"/with_ae_acc.png\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4528,"status":"ok","timestamp":1689750636475,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"DOLmqMay1HEl"},"outputs":[],"source":["# Make predictions\n","test_accuracy_1, y_test_pred_1, test_confidences_1 = get_accuracy( test_loader_1, device, classifier )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Make predictions\n","train_accuracy_1, y_train_pred_1, train_confidences_1 = get_accuracy( train_loader_1, device, classifier )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cjd7U0GTb3x_"},"outputs":[],"source":["# Plot the confusion matrix as a heatmap\n","plot_confusion_matrix(confusion_matrix(y_test_1, y_test_pred_1), results_dir+\"with_ae_cm\", classes=class_names_1, title='Confusion Matrix {}%'.format(test_accuracy_1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6juaJKR1pEtt"},"outputs":[],"source":["print(plot_classification_report(classification_report(y_test_1, y_test_pred_1), results_dir+\"with_ae_cr\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1689750658013,"user":{"displayName":"Asitha Indrajith","userId":"04609926954234524709"},"user_tz":-600},"id":"bdvJFWagmjHO"},"outputs":[],"source":["print(plot_roc(y_test_1, np.vstack([tensor.cpu().numpy() for tensor in test_confidences_1]), 2, 'Receiver operating characteristic', results_dir+\"with_ae_roc.png\"))"]},{"cell_type":"markdown","metadata":{},"source":["### 4.4 Training the VQC model"]},{"cell_type":"markdown","metadata":{"id":"Q7OACOP2kEuC"},"source":["#### 4.4.1 Generate 2048 feature vector from pre-trained encoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_2048_train_1, y_2048_train_1 = convert_2048_features(train_loader_1, device, encoder)\n","x_2048_test_1, y_2048_test_1 = convert_2048_features(test_loader_1, device, encoder)\n"]},{"cell_type":"markdown","metadata":{},"source":["#### 4.4.2 Scale the generated data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_2048_train_1 = scale_dataset(x_2048_train_1)\n","x_2048_test_1 = scale_dataset(x_2048_test_1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_2048_train_1.extend(x_2048_test_1)\n","y_2048_train_1.extend(y_2048_test_1)"]},{"cell_type":"markdown","metadata":{},"source":["#### 4.4.3 Create new dataset using generated data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df_train_1 = create_new_dataframe_and_save_csv(x_2048_train_1, y_2048_train_1, 2048, models_dir, 'train_loader_1_df')\n","merged_df_test_1 = create_new_dataframe_and_save_csv(x_2048_test_1, y_2048_test_1, 2048, models_dir, 'test_loader_1_df')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# merged_df_train_1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# X_train_2048, X_test_2048, y_train_2048, y_test_2048 = train_test_split(x_2048_train_1, y_2048_train_1, test_size=0.16, random_state=42, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["#### 4.4.4 Principal component analysis (PCA) to reduce feature dimension"]},{"cell_type":"markdown","metadata":{},"source":["##### 4.4.4.1 Transform 2048 features using PCA"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pca_30 = make_pipeline( PCA(n_components=100, random_state=42), MinMaxScaler() ) # scale data to min max range after pca\n","pca_30.fit(x_2048_train_1)\n","X_pca_30 = pca_30.transform(x_2048_train_1)"]},{"cell_type":"markdown","metadata":{},"source":["##### 4.4.4.2 Plot explained variance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(np.cumsum(pca_30.get_params()['pca'].explained_variance_ratio_)) \n","plt.xlabel('Number of components')\n","plt.ylabel('Explained variance') \n","plt.savefig('elbow_plot.png', dpi=100)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pca_2 = make_pipeline( PCA(n_components=2, random_state=42), MinMaxScaler() )\n","pca_2.fit(x_2048_train_1)\n","X_train_pca_2_1 = pca_2.transform(x_2048_train_1)\n","X_test_pca_2_1 = pca_2.transform(x_2048_test_1)"]},{"cell_type":"markdown","metadata":{},"source":["### 4.5 Convert data labels using one-hot encoding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","oh_encoder = OneHotEncoder()\n","train_labels_oh = oh_encoder.fit_transform(y_2048_train_1.reshape(-1, 1)\n","                                       ).toarray()\n","test_labels_oh = oh_encoder.fit_transform(y_2048_test_1.reshape(-1, 1)\n","                                      ).toarray()"]},{"cell_type":"markdown","metadata":{},"source":["### 4.6 Generate random initial points for gradient decent to avoid barren plateau problem"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["initial_point = np.random.random(VAR_FORM.num_parameters)"]},{"cell_type":"markdown","metadata":{},"source":["### 4.7 Training VQC"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["log = OptimizerLog()\n","vqc_1 = VQC(feature_map=FEATURE_MAP,\n","          ansatz=VAR_FORM,\n","          loss='cross_entropy',\n","          optimizer=SPSA( callback=log.update ),\n","          initial_point=initial_point,\n","          quantum_instance=BasicAer.get_backend('qasm_simulator'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vqc_1.fit(X_train_pca_2_1, train_labels_oh)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure()\n","plt.plot(log.evaluations, log.costs)\n","plt.xlabel('Steps')\n","plt.ylabel('Cost')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# score == accuracy\n","vqc_accuracy_1 = vqc_1.score(X_test_pca_2_1, test_labels_oh)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred_test_labels_oh_1 = vqc_1.predict(X_test_pca_2_1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vqc_pred_test_labels_1 = np.argmax(pred_test_labels_oh_1, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the confusion matrix as a heatmap\n","plot_confusion_matrix(confusion_matrix(y_2048_test_1, vqc_pred_test_labels_1), results_dir+\"with_VQC_cm.png\", classes=class_names_1, title='Confusion Matrix {}%'.format(vqc_accuracy*100))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMZWAJKGicTv8+ECIc9HBL6","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
